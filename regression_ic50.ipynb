{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:39:05.092585Z",
     "start_time": "2025-08-03T07:39:05.089048Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c5f152fc9a9b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:39:06.550456Z",
     "start_time": "2025-08-03T07:39:06.547077Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    df = pd.read_excel(file_path)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "    feature_cols = [c for c in df.columns if c not in [\"IC50, mM\", \"CC50, mM\", \"SI\"]]\n",
    "    X = df[feature_cols]\n",
    "    y = np.log10(df[\"IC50, mM\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b439636653d005d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:39:15.710174Z",
     "start_time": "2025-08-03T07:39:15.705024Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_models(random_state: int = 42) -> Dict[str, Tuple[Pipeline, Dict[str, List]]]:\n",
    "    models: Dict[str, Tuple[Pipeline, Dict[str, List]]] = {}\n",
    "\n",
    "    # Ridge regression pipeline\n",
    "    ridge_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "    ridge_grid = {\n",
    "        'model__alpha': [1.0, 10.0],\n",
    "        'model__solver': ['auto']\n",
    "    }\n",
    "    models['Ridge'] = (ridge_pipe, ridge_grid)\n",
    "\n",
    "    # Lasso regression pipeline\n",
    "    lasso_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(random_state=random_state, max_iter=10000))\n",
    "    ])\n",
    "    lasso_grid = {\n",
    "        'model__alpha': [0.001, 0.01, 0.1],\n",
    "        'model__selection': ['cyclic']\n",
    "    }\n",
    "    models['Lasso'] = (lasso_pipe, lasso_grid)\n",
    "\n",
    "    # Random Forest Regressor pipeline\n",
    "    rf_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', RandomForestRegressor(random_state=random_state))\n",
    "    ])\n",
    "    rf_grid = {\n",
    "        'model__n_estimators': [200, 400],\n",
    "        'model__max_depth': [None, 10],\n",
    "        'model__min_samples_split': [2]\n",
    "    }\n",
    "    models['RandomForest'] = (rf_pipe, rf_grid)\n",
    "\n",
    "    # Gradient Boosting Regressor pipeline\n",
    "    gbr_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', GradientBoostingRegressor(random_state=random_state))\n",
    "    ])\n",
    "    gbr_grid = {\n",
    "        'model__n_estimators': [200],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__max_depth': [3, 5]\n",
    "    }\n",
    "    models['GradientBoosting'] = (gbr_pipe, gbr_grid)\n",
    "\n",
    "    # XGBoost Regressor pipeline\n",
    "    xgb_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', XGBRegressor(\n",
    "            random_state=random_state,\n",
    "            objective='reg:squarederror',\n",
    "            eval_metric='rmse',\n",
    "            tree_method='hist',\n",
    "            n_jobs=4\n",
    "        ))\n",
    "    ])\n",
    "    xgb_grid = {\n",
    "        'model__n_estimators': [400],\n",
    "        'model__max_depth': [3, 6],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__subsample': [0.8]\n",
    "    }\n",
    "    models['XGBoost'] = (xgb_pipe, xgb_grid)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb8c7c6dc1c4199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:39:28.960738Z",
     "start_time": "2025-08-03T07:39:28.956687Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models: Dict[str, Tuple[Pipeline, Dict[str, List]]], X: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "    results = []\n",
    "    scoring = {\n",
    "        'rmse': 'neg_root_mean_squared_error',\n",
    "        'mae': 'neg_mean_absolute_error',\n",
    "        'r2': 'r2'\n",
    "    }\n",
    "    for name, (pipe, param_grid) in models.items():\n",
    "        print(f\"\\n--- Optimising {name} ---\")\n",
    "        grid = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        grid.fit(X, y)\n",
    "        print(f\"Best parameters for {name}: {grid.best_params_}\")\n",
    "        best_model = grid.best_estimator_\n",
    "        cv_scores = cross_validate(best_model, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "        result = {\n",
    "            'Model': name,\n",
    "            'RMSE (mean)': -cv_scores['test_rmse'].mean(),\n",
    "            'RMSE (std)': cv_scores['test_rmse'].std(),\n",
    "            'MAE (mean)': -cv_scores['test_mae'].mean(),\n",
    "            'MAE (std)': cv_scores['test_mae'].std(),\n",
    "            'R2 (mean)': cv_scores['test_r2'].mean(),\n",
    "            'R2 (std)': cv_scores['test_r2'].std()\n",
    "        }\n",
    "        results.append(result)\n",
    "    results_df = pd.DataFrame(results).sort_values(by='RMSE (mean)')\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0a01eb906de5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:40:57.102967Z",
     "start_time": "2025-08-03T07:39:49.624936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimising Ridge ---\n",
      "Best parameters for Ridge: {'model__alpha': 10.0, 'model__solver': 'auto'}\n",
      "\n",
      "--- Optimising Lasso ---\n",
      "Best parameters for Lasso: {'model__alpha': 0.1, 'model__selection': 'cyclic'}\n",
      "\n",
      "--- Optimising RandomForest ---\n",
      "Best parameters for RandomForest: {'model__max_depth': 10, 'model__min_samples_split': 2, 'model__n_estimators': 400}\n",
      "\n",
      "--- Optimising GradientBoosting ---\n",
      "Best parameters for GradientBoosting: {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 200}\n",
      "\n",
      "--- Optimising XGBoost ---\n",
      "Best parameters for XGBoost: {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 400, 'model__subsample': 0.8}\n",
      "\n",
      "===== Cross‑validated performance summary =====\n",
      "           Model  RMSE (mean)  RMSE (std)  MAE (mean)  MAE (std)  R2 (mean)  R2 (std)\n",
      "         XGBoost       0.8669      0.1871      0.6807     0.1368     0.0397    0.2361\n",
      "GradientBoosting       0.8669      0.1940      0.6774     0.1323     0.0495    0.2086\n",
      "    RandomForest       0.8686      0.2026      0.6782     0.1390     0.0439    0.2400\n",
      "           Lasso       0.9122      0.1523      0.7197     0.0887    -0.0577    0.1203\n",
      "           Ridge       1.0738      0.1972      0.8282     0.1275    -0.4690    0.2455\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('data.xlsx')\n",
    "X, y = load_and_prepare_data(data_path)\n",
    "models = build_models()\n",
    "results_df = evaluate_models(models, X, y)\n",
    "print(\"\\n===== Cross‑validated performance summary =====\")\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "results_df.to_csv('regression_ic50_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
