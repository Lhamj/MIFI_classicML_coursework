{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9107f20b894e725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:42:42.260568Z",
     "start_time": "2025-08-03T07:42:41.207816Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b416befeb58f18a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:42:48.009944Z",
     "start_time": "2025-08-03T07:42:48.007054Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    df = pd.read_excel(file_path)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "    feature_cols = [c for c in df.columns if c not in [\"IC50, mM\", \"CC50, mM\", \"SI\"]]\n",
    "    X = df[feature_cols]\n",
    "    y = np.log10(df[\"SI\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503100062c6865f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:42:59.874957Z",
     "start_time": "2025-08-03T07:42:59.869912Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_models(random_state: int = 42) -> Dict[str, Tuple[Pipeline, Dict[str, List]]]:\n",
    "    models: Dict[str, Tuple[Pipeline, Dict[str, List]]] = {}\n",
    "    # Ridge regression\n",
    "    ridge_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Ridge())\n",
    "    ])\n",
    "    ridge_grid = {\n",
    "        'model__alpha': [1.0, 10.0],\n",
    "        'model__solver': ['auto']\n",
    "    }\n",
    "    models['Ridge'] = (ridge_pipe, ridge_grid)\n",
    "    # Lasso\n",
    "    lasso_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', Lasso(random_state=random_state, max_iter=10000))\n",
    "    ])\n",
    "    lasso_grid = {\n",
    "        'model__alpha': [0.001, 0.01, 0.1],\n",
    "        'model__selection': ['cyclic']\n",
    "    }\n",
    "    models['Lasso'] = (lasso_pipe, lasso_grid)\n",
    "    # Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', RandomForestRegressor(random_state=random_state))\n",
    "    ])\n",
    "    rf_grid = {\n",
    "        'model__n_estimators': [200, 400],\n",
    "        'model__max_depth': [None, 10],\n",
    "        'model__min_samples_split': [2]\n",
    "    }\n",
    "    models['RandomForest'] = (rf_pipe, rf_grid)\n",
    "    # Gradient Boosting\n",
    "    gbr_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', GradientBoostingRegressor(random_state=random_state))\n",
    "    ])\n",
    "    gbr_grid = {\n",
    "        'model__n_estimators': [200],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__max_depth': [3, 5]\n",
    "    }\n",
    "    models['GradientBoosting'] = (gbr_pipe, gbr_grid)\n",
    "    # XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', XGBRegressor(\n",
    "            random_state=random_state,\n",
    "            objective='reg:squarederror',\n",
    "            eval_metric='rmse',\n",
    "            tree_method='hist',\n",
    "            n_jobs=4\n",
    "        ))\n",
    "    ])\n",
    "    xgb_grid = {\n",
    "        'model__n_estimators': [400],\n",
    "        'model__max_depth': [3, 6],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__subsample': [0.8]\n",
    "    }\n",
    "    models['XGBoost'] = (xgb_pipe, xgb_grid)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7d11e6c06618bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:43:08.067209Z",
     "start_time": "2025-08-03T07:43:08.063085Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models: Dict[str, Tuple[Pipeline, Dict[str, List]]], X: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "    scoring = {\n",
    "        'rmse': 'neg_root_mean_squared_error',\n",
    "        'mae': 'neg_mean_absolute_error',\n",
    "        'r2': 'r2'\n",
    "    }\n",
    "    results = []\n",
    "    for name, (pipe, grid) in models.items():\n",
    "        print(f\"\\n--- Optimising {name} ---\")\n",
    "        gs = GridSearchCV(\n",
    "            pipe,\n",
    "            grid,\n",
    "            cv=5,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        gs.fit(X, y)\n",
    "        print(f\"Best parameters for {name}: {gs.best_params_}\")\n",
    "        best = gs.best_estimator_\n",
    "        cv_scores = cross_validate(best, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'RMSE (mean)': -cv_scores['test_rmse'].mean(),\n",
    "            'RMSE (std)': cv_scores['test_rmse'].std(),\n",
    "            'MAE (mean)': -cv_scores['test_mae'].mean(),\n",
    "            'MAE (std)': cv_scores['test_mae'].std(),\n",
    "            'R2 (mean)': cv_scores['test_r2'].mean(),\n",
    "            'R2 (std)': cv_scores['test_r2'].std()\n",
    "        })\n",
    "    results_df = pd.DataFrame(results).sort_values(by='RMSE (mean)')\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6733efa986740d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:44:26.593935Z",
     "start_time": "2025-08-03T07:43:24.724149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimising Ridge ---\n",
      "Best parameters for Ridge: {'model__alpha': 10.0, 'model__solver': 'auto'}\n",
      "\n",
      "--- Optimising Lasso ---\n",
      "Best parameters for Lasso: {'model__alpha': 0.1, 'model__selection': 'cyclic'}\n",
      "\n",
      "--- Optimising RandomForest ---\n",
      "Best parameters for RandomForest: {'model__max_depth': 10, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "\n",
      "--- Optimising GradientBoosting ---\n",
      "Best parameters for GradientBoosting: {'model__learning_rate': 0.05, 'model__max_depth': 5, 'model__n_estimators': 200}\n",
      "\n",
      "--- Optimising XGBoost ---\n",
      "Best parameters for XGBoost: {'model__learning_rate': 0.05, 'model__max_depth': 6, 'model__n_estimators': 400, 'model__subsample': 0.8}\n",
      "\n",
      "===== Cross‑validated performance summary =====\n",
      "           Model  RMSE (mean)  RMSE (std)  MAE (mean)  MAE (std)  R2 (mean)  R2 (std)\n",
      "    RandomForest       0.7518      0.1393      0.5899     0.1083    -0.1053    0.1111\n",
      "           Lasso       0.7555      0.1386      0.6046     0.0950    -0.1201    0.1445\n",
      "GradientBoosting       0.7658      0.1199      0.5943     0.0904    -0.1636    0.1539\n",
      "         XGBoost       0.7706      0.1295      0.5992     0.1000    -0.1718    0.1444\n",
      "           Ridge       0.9070      0.1472      0.6948     0.0848    -0.6767    0.4488\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('data.xlsx')\n",
    "X, y = load_and_prepare_data(data_path)\n",
    "models = build_models()\n",
    "results_df = evaluate_models(models, X, y)\n",
    "print(\"\\n===== Cross‑validated performance summary =====\")\n",
    "print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "results_df.to_csv('regression_si_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
