{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:46:39.348992Z",
     "start_time": "2025-08-03T07:46:39.345841Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9281923ab4a10ffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:46:50.168030Z",
     "start_time": "2025-08-03T07:46:50.164850Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    df = pd.read_excel(file_path)\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "    median_cc50 = df[\"CC50, mM\"].median()\n",
    "    y = (df[\"CC50, mM\"] > median_cc50).astype(int)\n",
    "    feature_cols = [c for c in df.columns if c not in [\"IC50, mM\", \"CC50, mM\", \"SI\"]]\n",
    "    X = df[feature_cols]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ddba8cb0236297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:47:02.172345Z",
     "start_time": "2025-08-03T07:47:02.167609Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_models(random_state: int = 42) -> Dict[str, Tuple[Pipeline, Dict[str, List]]]:\n",
    "    models: Dict[str, Tuple[Pipeline, Dict[str, List]]] = {}\n",
    "    # Logistic Regression\n",
    "    log_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=500, random_state=random_state))\n",
    "    ])\n",
    "    log_grid = {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    }\n",
    "    models['LogisticRegression'] = (log_pipe, log_grid)\n",
    "    # Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', RandomForestClassifier(random_state=random_state))\n",
    "    ])\n",
    "    rf_grid = {\n",
    "        'model__n_estimators': [200, 400],\n",
    "        'model__max_depth': [None, 10],\n",
    "        'model__min_samples_split': [2],\n",
    "        'model__class_weight': [None, 'balanced']\n",
    "    }\n",
    "    models['RandomForest'] = (rf_pipe, rf_grid)\n",
    "    # Gradient Boosting\n",
    "    gb_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', GradientBoostingClassifier(random_state=random_state))\n",
    "    ])\n",
    "    gb_grid = {\n",
    "        'model__n_estimators': [200],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__max_depth': [3, 5]\n",
    "    }\n",
    "    models['GradientBoosting'] = (gb_pipe, gb_grid)\n",
    "    # XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', XGBClassifier(\n",
    "            random_state=random_state,\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            tree_method='hist',\n",
    "            n_jobs=4\n",
    "        ))\n",
    "    ])\n",
    "    xgb_grid = {\n",
    "        'model__n_estimators': [400],\n",
    "        'model__max_depth': [3, 6],\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__subsample': [0.8],\n",
    "        'model__scale_pos_weight': [1]\n",
    "    }\n",
    "    models['XGBoost'] = (xgb_pipe, xgb_grid)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2dc90d0ac9829ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:47:11.720825Z",
     "start_time": "2025-08-03T07:47:11.716603Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models: Dict[str, Tuple[Pipeline, Dict[str, List]]], X: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "    scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1',\n",
    "        'roc_auc': 'roc_auc'\n",
    "    }\n",
    "    results = []\n",
    "    for name, (pipe, grid) in models.items():\n",
    "        print(f\"\\n--- Optimising {name} ---\")\n",
    "        gcv = GridSearchCV(\n",
    "            pipe,\n",
    "            grid,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        gcv.fit(X, y)\n",
    "        print(f\"Best parameters for {name}: {gcv.best_params_}\")\n",
    "        best = gcv.best_estimator_\n",
    "        cv_scores = cross_validate(best, X, y, cv=5, scoring=scoring, n_jobs=-1)\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy (mean)': cv_scores['test_accuracy'].mean(),\n",
    "            'Accuracy (std)': cv_scores['test_accuracy'].std(),\n",
    "            'Precision (mean)': cv_scores['test_precision'].mean(),\n",
    "            'Precision (std)': cv_scores['test_precision'].std(),\n",
    "            'Recall (mean)': cv_scores['test_recall'].mean(),\n",
    "            'Recall (std)': cv_scores['test_recall'].std(),\n",
    "            'F1 (mean)': cv_scores['test_f1'].mean(),\n",
    "            'F1 (std)': cv_scores['test_f1'].std(),\n",
    "            'ROC_AUC (mean)': cv_scores['test_roc_auc'].mean(),\n",
    "            'ROC_AUC (std)': cv_scores['test_roc_auc'].std()\n",
    "        })\n",
    "    results_df = pd.DataFrame(results).sort_values(by='ROC_AUC (mean)', ascending=False)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65d5ca02f6aed2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T07:48:08.365503Z",
     "start_time": "2025-08-03T07:47:36.060106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimising LogisticRegression ---\n",
      "Best parameters for LogisticRegression: {'model__C': 0.1, 'model__class_weight': 'balanced'}\n",
      "\n",
      "--- Optimising RandomForest ---\n",
      "Best parameters for RandomForest: {'model__class_weight': None, 'model__max_depth': None, 'model__min_samples_split': 2, 'model__n_estimators': 200}\n",
      "\n",
      "--- Optimising GradientBoosting ---\n",
      "Best parameters for GradientBoosting: {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 200}\n",
      "\n",
      "--- Optimising XGBoost ---\n",
      "Best parameters for XGBoost: {'model__learning_rate': 0.05, 'model__max_depth': 6, 'model__n_estimators': 400, 'model__scale_pos_weight': 1, 'model__subsample': 0.8}\n",
      "\n",
      "===== Cross‑validated performance summary =====\n",
      "             Model  Accuracy (mean)  Accuracy (std)  Precision (mean)  Precision (std)  Recall (mean)  Recall (std)  F1 (mean)  F1 (std)  ROC_AUC (mean)  ROC_AUC (std)\n",
      "  GradientBoosting           0.5793          0.0905            0.5765           0.0926         0.6536        0.0841     0.6091    0.0733          0.5964         0.0995\n",
      "LogisticRegression           0.5644          0.0762            0.5683           0.0730         0.6175        0.0767     0.5864    0.0486          0.5939         0.0977\n",
      "           XGBoost           0.5623          0.0818            0.5577           0.0732         0.6595        0.0653     0.6019    0.0593          0.5775         0.1173\n",
      "      RandomForest           0.5673          0.0907            0.5675           0.0866         0.6455        0.0545     0.6009    0.0611          0.5726         0.1205\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('data.xlsx')\n",
    "X, y = load_and_prepare_data(data_path)\n",
    "models = build_models()\n",
    "results_df = evaluate_models(models, X, y)\n",
    "print(\"\\n===== Cross‑validated performance summary =====\")\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(results_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "results_df.to_csv('classification_cc50_median_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
